{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dazai_text_generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fq6WdNoqrnOj"
      },
      "source": [
        "# RNNで太宰治風の文章生成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TmlcsSA1ofzv"
      },
      "source": [
        "## 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RQ_kMJF-sLzn"
      },
      "source": [
        "### ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "2w8kK5Ri7kX5",
        "outputId": "f1d0a627-074d-4a4e-e22a-0b5e82aceb0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.4.0\n"
          ]
        }
      ],
      "source": [
        "import time, math, random, pickle\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "import torch.nn as nn \n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R-e4EfKrrpTU"
      },
      "source": [
        "### GPUを利用する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "AGndF5rbrsdX",
        "outputId": "30ff836f-b6dd-455e-f595-858233e9e93c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pCXQiAURUcBE"
      },
      "source": [
        "## データの読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pjALKdJidgci"
      },
      "source": [
        "### 学習済み単語ベクトル(chiVeより作成)をロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xNMqkuU9pzGs"
      },
      "outputs": [],
      "source": [
        "filename = './data/emb_layer_50k.npy'\n",
        "with open(filename, 'rb') as f:\n",
        "  emb_layer = np.load(f)\n",
        "  unk_vec = np.sum(emb_layer, axis=0) / len(emb_layer)\n",
        "\n",
        "  emb_layer = np.append(emb_layer, unk_vec.reshape(1, -1), axis=0)\n",
        "  embeddings = torch.tensor(emb_layer, dtype=torch.float, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "du7s1Phb0AeV"
      },
      "source": [
        "### 単語と単語IDを変換する辞書をロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "v30qYV360AK-"
      },
      "outputs": [],
      "source": [
        "filename = './data/word2id_50k.pkl'\n",
        "with open(filename, 'rb') as f:\n",
        "  word_to_id = pickle.load(f)\n",
        "  id_to_word = {v: k for k, v in word_to_id.items()}\n",
        "\n",
        "  dict_len = len(word_to_id)\n",
        "  word_to_id['<unk>'] = dict_len\n",
        "  id_to_word[dict_len] = '<unk>'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0XGy-VrtdoQB"
      },
      "source": [
        "### コーパスをロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "nG8kZDTjdsKR",
        "outputId": "f643aedd-0005-4d76-c2e9-0867602af657"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1385480\n"
          ]
        }
      ],
      "source": [
        "corpus = np.array([], dtype=int)\n",
        "\n",
        "corpus_dir = Path('./data/corpus')\n",
        "for file_path in corpus_dir.glob('*.npy'):\n",
        "  if not file_path.exists():\n",
        "    print(file_path + ' does not exist!')\n",
        "    continue\n",
        "  with open(file_path, 'rb') as f:\n",
        "    corpus = np.concatenate((corpus, np.load(f)))\n",
        "\n",
        "print(len(corpus))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c6IkDHiE9anQ"
      },
      "source": [
        "## 入力データの整形"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LdqA-9bKpdDK"
      },
      "source": [
        "### 訓練データ、検証データ、テストデータに分割"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "CCfR6tJupi6S",
        "outputId": "ecbb7f18-f1eb-4324-87a1-bdb1fc9c37ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1108384 138548 138548\n"
          ]
        }
      ],
      "source": [
        "train_ratio = 0.8\n",
        "val_ratio = 0.1\n",
        "\n",
        "size = len(corpus)\n",
        "train_size = math.floor(size * train_ratio)\n",
        "val_size = math.floor(size * val_ratio)\n",
        "\n",
        "train = torch.tensor(corpus[:train_size], dtype=torch.long, device=device)\n",
        "val = torch.tensor(corpus[train_size:train_size + val_size],\n",
        "                   dtype=torch.long, device=device)\n",
        "test = torch.tensor(corpus[train_size + val_size:],\n",
        "                    dtype=torch.long, device=device)\n",
        "print(len(train), len(val), len(test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kTljuwiU7AFT"
      },
      "source": [
        "### ミニバッチ化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "oSrdUOFCQRuS",
        "outputId": "3ae9e59b-f931-4f95-b83c-9f211f70b25a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1584 198 198\n"
          ]
        }
      ],
      "source": [
        "class MyBPTTIterator(object):\n",
        "  \"\"\"Return given data in the shape of (seq_len, batch_size)\"\"\"\n",
        "\n",
        "  def __init__(self, data, batch_size, bptt_len):\n",
        "    nbatch = data.size(0) // batch_size\n",
        "    data = data.narrow(0, 0, nbatch * batch_size)\n",
        "    self.data = data.view(batch_size, -1).t().contiguous()\n",
        "    self.batch_size = batch_size\n",
        "    self.bptt_len = bptt_len\n",
        "\n",
        "  @classmethod\n",
        "  def splits(cls, datasets, batch_size, bptt_len):\n",
        "    ret = []\n",
        "    for data in datasets:\n",
        "      ret.append(cls(data, batch_size, bptt_len))\n",
        "    return tuple(ret)\n",
        "\n",
        "  def __len__(self):\n",
        "    return math.ceil((len(self.data) - 1 ) / self.bptt_len)\n",
        "  \n",
        "  def __iter__(self):\n",
        "    for i in range(0, len(self.data) - 1, self.bptt_len):\n",
        "      seq_len = min(self.bptt_len, len(self.data) - 1 - i)\n",
        "      text = self.data[i:i + seq_len]\n",
        "      target = self.data[i + 1:i + 1 + seq_len]\n",
        "      yield text, target\n",
        "\n",
        "\n",
        "batch_size = 20\n",
        "bptt_len = 35\n",
        "\n",
        "train_iter, val_iter, test_iter = MyBPTTIterator.splits(\n",
        "    (train, val, test), batch_size, bptt_len)\n",
        "print(len(train_iter), len(val_iter), len(test_iter))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tXxgYGbgsooa"
      },
      "source": [
        "## モデルの構築"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PAJ7M3tU7xu1"
      },
      "outputs": [],
      "source": [
        "class MyLSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, emb_dim, hidden_size, dropout=0.5,\n",
        "               embeddings=None, freeze=False, weight_tied=False):\n",
        "    super(MyLSTM, self).__init__()\n",
        "\n",
        "    if embeddings is not None:\n",
        "      weight_size = (vocab_size, emb_dim)\n",
        "      if embeddings.size() != weight_size:\n",
        "        raise ValueError(\n",
        "            f'Expected weight size {weight_size}, got {embeddings.size()}')\n",
        "      self.embed = nn.Embedding.from_pretrained(embeddings, freeze=freeze)\n",
        "    else:\n",
        "      self.embed = nn.Embedding(vocab_size, emb_dim)\n",
        "    self.dropout1 = nn.Dropout(dropout)\n",
        "    self.lstm1 = nn.LSTM(emb_dim, hidden_size)\n",
        "    self.dropout2 = nn.Dropout(dropout)\n",
        "    self.lstm2 = nn.LSTM(hidden_size, emb_dim)\n",
        "    self.dropout3 = nn.Dropout(dropout)\n",
        "    self.linear = nn.Linear(emb_dim, vocab_size)\n",
        "\n",
        "    nn.init.normal_(self.embed.weight, std=0.01)\n",
        "    nn.init.normal_(self.lstm1.weight_ih_l0, std=1/math.sqrt(emb_dim))\n",
        "    nn.init.normal_(self.lstm1.weight_hh_l0, std=1/math.sqrt(hidden_size))\n",
        "    nn.init.zeros_(self.lstm1.bias_ih_l0)\n",
        "    nn.init.zeros_(self.lstm1.bias_hh_l0)\n",
        "    nn.init.normal_(self.lstm2.weight_ih_l0, std=1/math.sqrt(hidden_size))\n",
        "    nn.init.normal_(self.lstm2.weight_hh_l0, std=1/math.sqrt(hidden_size))\n",
        "    nn.init.zeros_(self.lstm2.bias_ih_l0)\n",
        "    nn.init.zeros_(self.lstm2.bias_hh_l0)\n",
        "    if weight_tied:\n",
        "      self.linear.weight = self.embed.weight\n",
        "    else:\n",
        "      nn.init.normal_(self.linear.weight, std=1/math.sqrt(emb_dim))\n",
        "    nn.init.zeros_(self.linear.bias)\n",
        "\n",
        "  def forward(self, input, hidden_prev):\n",
        "    if hidden_prev is None:\n",
        "      hidden1_prev, hidden2_prev = None, None\n",
        "    else:\n",
        "      hidden1_prev = hidden_prev[0:2]\n",
        "      hidden2_prev = hidden_prev[2:4]\n",
        "    \n",
        "    emb_out = self.embed(input)\n",
        "    emb_out = self.dropout1(emb_out)\n",
        "    lstm1_out, hidden1_next = self.lstm1(emb_out, hidden1_prev)\n",
        "    lstm1_out = self.dropout2(lstm1_out)\n",
        "    lstm2_out, hidden2_next = self.lstm2(lstm1_out, hidden2_prev)\n",
        "    lstm2_out = self.dropout3(lstm2_out)\n",
        "    output = self.linear(lstm2_out)\n",
        "\n",
        "    hidden_next = hidden1_next + hidden2_next\n",
        "    return output, hidden_next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DzbwCDtODjRV"
      },
      "source": [
        "### パープレキシティを評価する関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VfDHCv6VDoBM"
      },
      "outputs": [],
      "source": [
        "def eval_perplexity(model, iterator):\n",
        "  total_loss = 0\n",
        "  hidden = None\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for input, target in iterator:\n",
        "      output, hidden = model(input, hidden)\n",
        "      loss = F.cross_entropy(output.view(-1, vocab_size), target.view(-1))\n",
        "      total_loss += loss.item()\n",
        "  \n",
        "  ppl = math.exp(total_loss / len(iterator))\n",
        "  return ppl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a9enEH40suiK"
      },
      "source": [
        "## モデルの学習\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UXau95pgy4sY"
      },
      "source": [
        "### 学習準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "TgFvqOWGQUk8",
        "outputId": "9b90e9fe-191c-444e-9f51-832e5ab19510"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50001 300\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(word_to_id)\n",
        "emb_dim = embeddings.size()[1]\n",
        "print(vocab_size, emb_dim)\n",
        "\n",
        "hidden_size = emb_dim\n",
        "dropout = 0.5\n",
        "learning_rate = 20.0\n",
        "\n",
        "model = MyLSTM(vocab_size, emb_dim, hidden_size, dropout,\n",
        "               embeddings, freeze=False, weight_tied=True)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WVJbMWy66thJ"
      },
      "source": [
        "### 学習の実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "colab_type": "code",
        "id": "glyiYgOf6vWY",
        "outputId": "63431273-7ffd-424f-fdc6-6ee2d9b8fd91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial ppl : 49999.77\n",
            "| epoch 1 : valid perplexity 73.41  time 53.60s |\n",
            "| epoch 2 : valid perplexity 61.14  time 55.07s |\n",
            "| epoch 3 : valid perplexity 58.96  time 56.05s |\n",
            "| epoch 4 : valid perplexity 56.09  time 56.94s |\n",
            "| epoch 5 : valid perplexity 53.60  time 57.32s |\n",
            "| epoch 6 : valid perplexity 51.63  time 57.26s |\n",
            "| epoch 7 : valid perplexity 50.91  time 57.25s |\n",
            "| epoch 8 : valid perplexity 50.88  time 57.29s |\n",
            "| epoch 9 : valid perplexity 50.33  time 57.28s |\n",
            "| epoch 10 : valid perplexity 50.01  time 57.29s |\n",
            "| epoch 11 : valid perplexity 48.89  time 57.31s |\n",
            "| epoch 12 : valid perplexity 48.24  time 57.30s |\n",
            "| epoch 13 : valid perplexity 48.80  time 57.28s |\n",
            "| epoch 14 : valid perplexity 46.24  time 57.30s |\n",
            "| epoch 15 : valid perplexity 45.97  time 57.31s |\n",
            "| epoch 16 : valid perplexity 45.64  time 57.32s |\n",
            "| epoch 17 : valid perplexity 45.61  time 57.33s |\n",
            "| epoch 18 : valid perplexity 45.57  time 57.34s |\n",
            "| epoch 19 : valid perplexity 45.49  time 57.36s |\n",
            "| epoch 20 : valid perplexity 45.36  time 57.35s |\n",
            "| epoch 21 : valid perplexity 45.09  time 57.34s |\n",
            "| epoch 22 : valid perplexity 45.21  time 57.34s |\n",
            "| epoch 23 : valid perplexity 44.50  time 57.37s |\n",
            "| epoch 24 : valid perplexity 44.44  time 57.34s |\n",
            "| epoch 25 : valid perplexity 44.38  time 57.36s |\n",
            "| epoch 26 : valid perplexity 44.41  time 57.35s |\n",
            "| epoch 27 : valid perplexity 44.16  time 57.38s |\n",
            "| epoch 28 : valid perplexity 44.17  time 57.36s |\n",
            "| epoch 29 : valid perplexity 44.11  time 57.35s |\n",
            "| epoch 30 : valid perplexity 44.10  time 57.35s |\n"
          ]
        }
      ],
      "source": [
        "max_epoch = 30\n",
        "max_norm = 0.25\n",
        "\n",
        "total_loss, loss_count = 0, 0\n",
        "ppl_list = []\n",
        "best_ppl = float('inf')\n",
        "save_path = './data/model/weights.pth'\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "  model.train()\n",
        "  hidden = None\n",
        "  start = time.time()\n",
        "\n",
        "  for i, iters in enumerate(train_iter):\n",
        "    input, target = iters\n",
        "    optimizer.zero_grad()\n",
        "    output, hidden = model(input, hidden)\n",
        "    loss = criterion(output.view(-1, vocab_size), target.view(-1))\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
        "    optimizer.step()\n",
        "    hidden = tuple(h.detach() for h in hidden)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    loss_count += 1\n",
        "    if i % 500 == 0:\n",
        "      ppl = math.exp(total_loss / loss_count)\n",
        "      ppl_list.append(ppl)\n",
        "      total_loss, loss_count = 0, 0\n",
        "      if epoch == 0 and i == 0:\n",
        "        print(f'initial ppl : {ppl:.2f}')\n",
        "\n",
        "  val_ppl = eval_perplexity(model, val_iter)\n",
        "  t = time.time() - start\n",
        "  print(f'| epoch {epoch+1} : valid perplexity {val_ppl:.2f}  time {t:.2f}s |')\n",
        "  if val_ppl < best_ppl:\n",
        "    best_ppl = val_ppl\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "  else:\n",
        "    learning_rate /= 4.0\n",
        "    for group in optimizer.param_groups:\n",
        "      group['lr'] = learning_rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RG-X9uhx0cOI"
      },
      "source": [
        "### 学習結果のプロット"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "colab_type": "code",
        "id": "roB0l2e50e9v",
        "outputId": "fe5b158d-ecb3-419c-855f-911bb313e156"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3xV9f3H8dcne5IACQHC3iJbQARx\n17231llHW3ettXbXLrWtq/5aR+vAPXDg3lUUZK8wZMoIhA1hhOzP749zuUaahABJbsb7+XjwSO65\n5577OTnhvnO+33O+X3N3REREAKIiXYCIiDQcCgUREQlTKIiISJhCQUREwhQKIiISplAQEZEwhYI0\nC2b2iJn9JtJ17I2ZdTEzN7OYA9zOaDNbWFt1SfNhuk9BGjozWw5c7e4fR7qWumZmXYBvgFh3L63F\n7S6nmfwM5cDoTEEavQP9q7q+WED/56RB0y+oNGhm9gzQCXjLzHaY2e0VmliuMrOVwKehdV8xs7Vm\nlm9m483s4ArbecrM/hT6/igzyzWzn5rZejPLM7Mrq6nhMzO7y8ymmNk2MxtnZq0qPD/CzCaa2VYz\nm21mR+3x2j+b2QSgAOi2t+3t8d5pZvZ4qMbVZvYnM4sOPfewmb1aYd17zOyTUPgcZWa51fwM3zGz\nG/d4rzlmdlZNj400TQoFadDc/VJgJXCau6e4+18rPH0kcBBwQujxe0BPoA0wA3iumk23BdKAbOAq\n4J9m1rKa9S8DfgC0A0qBfwCYWTbwDvAnoBVwG/CqmWVWeO2lwLVAKrCiuu1V4qnQ8z2AwcDxwNWh\n534K9DezK8xsdGg/Lvc92oSr+BmOAS7ZvY6ZDQz9LN6p5mcgzYBCQRqz37v7TnffBeDuT7j7dncv\nAn4PDDSztCpeWwL8wd1L3P1dYAfQu5r3esbd57r7TuA3wPmhv9gvAd5193fdvdzdPwKmASdXeO1T\n7j7P3UvdvWQv2wszs6zQdm4J7ed64H7gwtD+FhAEzn3As8CN7p679x8bAG8CvcysZ+jxpcBL7l5c\nw9dLE6VQkMZs1e5vzCzazO42s6Vmtg1YHnoqo4rXbtqjI7cASKnJexH8tR8b2nZn4LxQ09FWM9sK\nHE5wBlDZa/e2vYo6h5bnVdj2owRnQgC4+2RgGWDAy9XU/x3uXgi8BFwS6ue4CHimpq+XpqtRdNBJ\ns1fVJXIVl18MnAEcRxAIacAWgg/L2tCxwvedCM40NhJ8uD/j7tdU89rK6q9qexWXrwKKgIyqrkQy\ns+uBeGANcDtw1z7UMIYgCL4ECtz9q2r2QZoJnSlIY7AO6LaXdVIJPkA3AUnAX2q5hkvMrK+ZJQF/\nAMa6exlBs81pZnZC6GwlIdTJ22E/txfm7nnAh8C9ZtbCzKLMrLuZHQlgZr0I+jIuIWj+ud3MBlXx\nfv/zMwyFQDlwLzpLkBCFgjQGdwG/DjWh3FbFOk8TNMOsBuYDk2q5hmcIOn3XAgnATQDuvorgDOWX\nwAaCv+5/xt7/b1W6vUpcBsQR7NMWYCzQLnQZ7rPAPe4+290Xh2p4xsziK9lOVT/Dp4H+oW2J6OY1\nkb0xs8+AZ939Pw1xewdYy2XAte5+eKRrkYZBZwoizVSo6eo64LFI1yINR52Fgpk9EboxaG6FZa3M\n7CMzWxz62jK03MzsH2a2JHQDzZC6qktEwMxOIGjuWgc8H+FypAGps+YjMzuC4Nrvp929X2jZX4HN\n7n63md0BtHT3n5vZycCNBNdkHwo86O6H1klhIiJSpTo7U3D38cDmPRafQXAZHKGvZ1ZY/rQHJgHp\nZtYOERGpV/V9n0JW6DI7CK66yAp9n813b+bJDS3LYw9mdi3BkAEkJycf0qdPn1otcNOOItbkF9K3\nXQuio2rrEncRkYZj+vTpG909s7LnInbzmru7me1z25W7P0aoY2zo0KE+bdq0Wq3rpakr+fmrObx9\nxzFkpyfW6rZFRBoCM1tR1XP1ffXRut3NQqGv60PLV/PdOzk7hJbVu8S4ICd3FdfaUPYiIo1GfYfC\nm8Dloe8vB8ZVWH5Z6CqkEUB+hWamepUUG4xJVlBctpc1RUSanjprPjKzF4CjgIzQuO6/A+4GXjaz\nqwjuPj0/tPq7BFceLSEYmKzKse3rWlKcQkFEmq86CwV3v6iKp46tZF0Hrq+rWvZFYigUdikURKQZ\n0h3Ne0gK9SnoTEFEmiOFwh6+bT5SR7OIND8KhT2Em49KdKYgIs2PQmEP6mgWkeZMobCHhBiFgog0\nXwqFPURFGYmx0bp5TUSaJYVCJZLionWmICLNkkKhEolx0bpPQUSaJYVCJXSmICLNlUKhEinxMWwr\nLIl0GSIi9U6hUIkurZNZtmFnpMsQEal3CoVK9MhKYe22Qp0tiEizo1CoRM82qQAsWb8jwpWIiNQv\nhUIlerZJARQKItL8KBQq0bFVEnExUQoFEWl2FAqViI4yumemsHjd9kiXIiJSrxQKVejZJoXFOlMQ\nkWZGoVCFnm1SyN2yS/MqiEizolCoQs+soLN56XrdryAizYdCoQo9QpelLl6vfgURaT4UClXo3DqJ\n2GhTv4KINCsKhSrERkfRNSOZxesUCiLSfCgUqtGzTSpL1HwkIs2IQqEaPdqksHJzAYUlGkZbRJoH\nhUI1emalUO6wdIOakESkeVAoVKNrRjIAKzcVRLgSEZH6oVCoRvu0RADW5BdGuBIRkfqhUKhGelIs\nCbFRrM3fFelSRETqhUKhGmZGu7REnSmISLOhUNiLdmkJ5G3VmYKINA8Khb1ol5ZIns4URKSZUCjs\nRfv0BNZtK6S0rDzSpYiI1DmFwl60S0uk3GH99qJIlyIiUucUCnvRLj0BgDxdgSQizYBCYS/C9yps\nVb+CiDR9EQkFM/uJmc0zs7lm9oKZJZhZVzObbGZLzOwlM4uLRG17apsWnCmsVWeziDQD9R4KZpYN\n3AQMdfd+QDRwIXAPcL+79wC2AFfVd22VaZEQQ3JcNGvUfCQizUCkmo9igEQziwGSgDzgGGBs6Pkx\nwJkRqu07zIx26YnkqflIRJqBeg8Fd18N/B1YSRAG+cB0YKu7l4ZWywWyK3u9mV1rZtPMbNqGDRvq\no+TgBjadKYhIMxCJ5qOWwBlAV6A9kAycWNPXu/tj7j7U3YdmZmbWUZXf1V5DXYhIMxGJ5qPjgG/c\nfYO7lwCvAaOA9FBzEkAHYHUEaqtUu/QENu4oorhUN7CJSNMWiVBYCYwwsyQzM+BYYD7wX+Dc0DqX\nA+MiUFul2qcl4g7rtulsQUSatkj0KUwm6FCeAeSEangM+Dlwq5ktAVoDj9d3bVX59gY2hYKING0x\ne1+l9rn774Df7bF4GTA8AuXsVbs03dUsIs2D7miugXa6q1lEmgmFQg0kx8fQIiFGZwoi0uQpFGqo\nfXoiOavz+cu7CzjxgfHMWLkl0iWJiNS6iPQpNEbt0xP59Ov15OTmU+7OB/PWMqRTy0iXJSJSqxQK\nNfTT43txfN8sjj+4LZc/MYW5q/MjXZKISK1TKNTQwe3TOLh9GgD9stN4Z84a3J3gVgsRkaZBfQr7\noX92GtsKS1m5uSDSpYiI1CqFwn7onx2cMeSoCUlEmhiFwn7o1TaFuOgohYKINDkKhf0QHxNN77ap\n6mwWkSZHobCf+mWnkZObj7tHuhQRkVqjUNhP6mwWkaZIobCfBnRQZ7OIND0Khf3UKytVnc0i0uQo\nFPZTXEwUvdumkpOrUBCRpkOhcAAGdkxjxsotLMjbFulSRERqhULhAPz4qB6kJ8Zx2RNTWLFpZ6TL\nERE5YAqFA5CdnsgzVw2npKycSx6fzHrN4SwijZxC4QD1zEplzJXDWZtfyOMTvol0OSIiB0ShUAsG\ndkynb/s05qxSp7OING4KhVrSP7sFc1fnU16uO5xFpPFSKNSS/tlpbC8qZYXucBaRRkyhUEv6Z6cD\nMCd3a4QrERHZfwqFWtIzK4W4mCiNnCoijZpCoZbERkfRt12L7wx7cfOLM3n6q+URq0lEZF8pFGpR\n/+w05q7eRnm5M3vVVsbNWsN/vvhGw2uLSKOhUKhF/TuksaOolOWbdvLspBUArNxcwIK87RGuTESk\nZhQKtWj33M0TlmzkrTlrOL5vFlEG789bG+HKRERqRqFQi3q2SSE+Jor7P15MYUk5Nx3bk2FdWvHB\nXIWCiDQOCoVaFBMdRd/2Ldi8s5hBHdPpl53Gif3asnDddpZt2BHp8kRE9kqhUMt2NyFdMqIzACcc\n3BaAD+ati1hNIiI1pVCoZacOaM9RvTM5dUA7ANqnJzKwQ5r6FUSkUYiJdAFNzfCurRjedfh3lp3Y\nrx33vP81h931CfExUZw3tCPXH90jQhWKiFRNZwr14IJhHfnBqK6M7plBVJTx1MTlundBRBqkiISC\nmaWb2Vgz+9rMFpjZYWbWysw+MrPFoa8tI1FbXWiVHMdvT+vLX88dyFWHd2XD9iKWb9LAeSLS8ETq\nTOFB4H137wMMBBYAdwCfuHtP4JPQ4ybn0K6tAZi8bFN42ctTV3HXewsiVZKISFi9h4KZpQFHAI8D\nuHuxu28FzgDGhFYbA5xZ37XVh+6ZyWSkxDH5m80AlJc7D3y8iEc/X8byjZrnWUQiq0ahYGbTzez6\nWmrS6QpsAJ40s5lm9h8zSway3D0vtM5aIKuKWq41s2lmNm3Dhg21UE79MjOGd23FlFAoTF+5hTX5\nwdzOL0xZGcnSRERqfKZwAdAemGpmL5rZCWZm+/meMcAQ4GF3HwzsZI+mIg96YSvtiXX3x9x9qLsP\nzczM3M8SIuvQrq1ZvXUXqzYX8NbsNcTHRDG6ZwavTM+lqLQs0uWJSDNWo1Bw9yXu/iugF/A88ASw\nwszuNLNW+/ieuUCuu08OPR5LEBLrzKwdQOjr+n3cbqNxaLfgR/bV0k28m5PHsQe14ZrR3di8s5j3\nNSSGiERQjfsUzGwAcC/wN+BV4DxgG/Dpvryhu68FVplZ79CiY4H5wJvA5aFllwPj9mW7jUmvNqmk\nJ8Xyr8+WsHFHMacPbM/hPTLo1CqJ5ycHTUg7ikrZtKMowpWKSHNTo5vXzGw6sJWgc/gOd9/9aTXZ\nzEbtx/veCDxnZnHAMuBKgoB62cyuAlYA5+/HdhuFqChjWJdWfDR/HSnxMRzVuw1RUcZFwztxz/tf\nc94jE5m5cispCTFM/uWxxMdER7pkEWkmanqmcJ67H+vuz+8OBDPrCuDuZ+/rm7r7rFC/wAB3P9Pd\nt7j7ptB79HT349x9875utzE5tGvQhHR83ywSYoMP/fOGdiAjJZ7thaV8r28WWwtKmLHi2zmft+ws\nZtys1brxTUTqTE1DYWwNl0kNHdW7DXHRwZAXu2WkxDPt18fx/i1H8NdzBxAdZXyx+NsrrB4Zv5Sb\nX5zF54sa31VXItI4VNt8ZGZ9gIOBNDOreEbQAkioy8Kauh5tUsi58/gqm4ZSE2IZ0imdL5ds5HbA\n3XlnTnDF7gMfL+bIXpns/wVgIiKV29uZQm/gVCAdOK3CvyHANXVbWtO3t76Cw3tkkrM6ny07i8lZ\nnU/ull0M79KKWau2Mn7xxnqqUkSak2pDwd3HufuVwKnufmWFfze5+8R6qrHZGt0rA3eYsHQj7+Tk\nERNl/N/3B9M+LYEHP16kvgURqXV7az663d3/ClxsZhft+by731RnlQkDstNITYjhi0UbmbhsI6N6\nZNAmNYHrju7Br9+Yy0OfLqFFQgzRUcbFh3YmOipoTiooLuWe977mx0f1oG2aWvlEpOb2dknq7lHa\nptV1IfK/YqKjGNU9g3GzV1NYUs6NR/cEgquUHvl8Kfd9tCi8bpsWCeFZ3t7NWcuYr1awvbCU+y4Y\nFJHaRaRxqjYU3P2t0LcvuXthxefMLKPOqpKw0b0yeH/eWmKijOMPDoaDio+J5p2bRpNfUEJiXDTf\nu/9z3s3JC4fC7ruiX5+1mh8e2Z3ebVMjVr+INC41vSR1ipmN2P3AzM4B1KdQD0b3CMZ3Gtkjg/Sk\nuPDytMRYOrVOIjM1nhP6tuWTBespLCljR1Ep4xdv4OzB2aTExfD3DxdGqnQRaYRqOh3n94EnzOwz\ngoHxWgPH1FVR8q1OrZO47qjuHNOnTZXrnDygHS9NW8X4RRsoKi2nuLScC4d3omtGMvd+tIiZK7cw\nuFPlA9w+OeEbDunckgEd0utqF0SkEalRKLh7jpn9GXgG2A4c4e65dVqZhN1+Yp9qnx/ZvTXpSbG8\nk5NHaZmTkRLPIZ1bcnD7Foz5ajlXPDmVhNgoikvL+du5Azmub9AMtWpzAXe+NZ/OrZP44JYjwndW\ni0jzVdP5FB4HbgEGEIxT9LaZXV+XhUnNxUZHhZuQ/rtwPccfnEV0lJEcH8PdZw/g8J4ZHNWrDTHR\nUYz5ann4dR/MC/oeVmwq4PEvv4lM8SLSoNS0TyEHONrdv3H3D4BDCW5gkwbi5AHt2FFUSkFxGSf1\naxteflzfLP558RDuOXcAFwztyIQlG1m/Pbhm4N2cPPq2a8GJB7floU8Xs3rrriq3v7OolO2FJXW+\nHyISWTWdT+EBIGH3cNfunu/uV9VpZbJPdjchpSXGMqJb60rXOXNwe8od3pqdx9r8Qmas3MrJ/dvy\n61MPAuD2sbP52wdf86NnpjNu1urvvPZHz07njP+bwM6i0jrfFxGJnJoOnX0a8HcgDuhqZoOAP7j7\n6XVZnNRcbHQUvzz5INyd2OjKs75Hm1T6Zbdg3KzVRIeGTTqxXzs6tEzixmN68rcPFjJ52WbiY6LI\nWZ3PaQPaExVlrNtWyJdLNuIOf3x7PnefM6Ae90xE6lNNm49+DwwnmFMBd58FdKujmmQ/nT+0IxcM\n61TtOmcOymZObj5PTlxOr6wUerRJAeC6o7oz/mdHM/8PJ/Lns/qzeusupiwPRi9/Z04e7nDKgHa8\nOHUV789dS3FpOR/NX8f4PUZs/Wzhen70zHR2FWtaUZHGqKahUOLu+XssK6/tYqTunTawPWZB5/KJ\n/dqFl5sZnVonERcTxfEHZ5EUF83rM4ImpLfnrOGgdi24//xB9Mtuwc9emc2wP3/MNU9P4+qnp5G/\n69u+hoc/W8r789by53fn1/u+iciBq2kozDOzi4FoM+tpZg+hm9capawWCYzsHvQ5nNy/baXrJMXF\ncGK/trybk8fSDTuYsXIrpw1sR1xMFA9eOJistASO6p3J707rS3FpeXhI7zVbdzH5m820T0vg2Ukr\n+XBe1fNNF5eW8/rMXApLdEYh0pDUNBRuJJhXoQh4gWBu5lvqqiipW7cc14sfHtGN3llVD39x9uAO\nbC8q5bZXZgNwav/2AHTPTOHjW4/kwQsHc8XILvTKSmHs9FUAvDl7DQBPXzWcftktuP3VOTz91XJ+\n/UYOt7486zsB8Mr0Vfzkpdn88vUcjfYq0oDU9OqjAnf/lbsPC02j+as9x0KSxmNYl1b84uSDqp2k\n57DurclqEc/MlVsZ2CGNTq2T/mcdM+OcIR2YsXIryzbs4I2ZqxncKZ0ebVJ58MLBFJWU89tx83ht\nxmpem7Gad3Pywq8dN3MNsdHGazNW8/yUlVXW4e68OGUlSzfsOLCdFpEa2dvQ2W8BVf4Zp6uPmq7o\nKOPMQdk8On4Zpw1sX+V6Zw3O5p73v+Yv737N12u3c+fpBwPBGcVHtx6BO2SnJ3LsfZ/zwpSVnD2k\nQ7gT+yfH9WLGyi3c+eZ8yh1yNxeweP0OfnnyQeEO8Dm5+dzxWg6ZqfG8+qORlYbTblsLiomPiSYx\nTndmi+yvvV2S+vd6qUIapEtGdGbJ+h2cOTi7ynXatEjgiF6ZfLxgHdFRxikDvu287tDy2w/wC4Z1\n5O73vmbJ+u18NH89EATKZYd15tSHvuQ3b8wlLjoKx/nXZ7Hcd34w5PerM3KJiwmG6Lj0icm88sPD\nWJNfyGcL13NMnzbhMZvcnfMe+Yqycuf160eRlhhbFz8SkSZvbzOvfb77H/AVsAXYDHwVWiZNWMdW\nSTx+xTAyUuKrXe+cIR0AGN0zo8p1zz2kA7HRxotTVjFuVtDM1Kl1Ei2T43jtupG8ft1Icu48nouG\nd+LtOXls2lFEUWkZb85ew/F9s3jyymGs31bEyLs/5cx/TuCBjxfz23HzwtufvmILi9fvYNnGndzy\n4kzKyqvup3h/bh63vjRLl82KVKKmN6+dAjwCLAWM4Aa2H7r7e3VZnDQO3+ubxRG9MrlmdNW3rmSk\nxPO9vlk8N3klu0rKws1MEFwRldUimCHu0hGdefqrFbw0bRXdMpLZWlDCuYd0YEinlvzn8qG8PG0V\nR/bKJHfLLu77aBE5ufn075DGqzNySYqL5uZje3LXe1/zx7fn06ZFPG/PzqNrZjL/vDgYlcXd+ev7\nC1m2cSebC4p57NKhxMXU9HoLkaavpkNn30sw9tESADPrDrwDKBSEhNhonv7B8L2ud9HwTrybs/Z/\nmpkq6pmVymHdWvPcpJX0bptKm9R4RvcM5pQY1SODUT2CuZ3yd5Xw8GdLeXbSCu4842Denp3HSf3a\nce0R3Vi+aSdPTVwOBP0Z78zJ48dH5tMvO41pK7awbONOju3Thk++Xs9PX5nNyO6teX3GajbuLOLd\nm0ZrtFhp1moaCtt3B0LIMoIhtEVqbFT3DLpmJNM9M7naJqnLR3bmR8/OYPXWXfzwiG7huacrSkuM\n5YxB7Xlj1mr6Zbdge1Ep5xySjZlx5+n9GNGtNUM6tSQtKZbD/vIJj3/5DfdfMIiXp64iOS6ahy4e\nzJiJK7jn/a95a/YaMlLi2bijiFmrtlY5dpRIc1DTUJhmZu8CLxNcjXQeMNXMzgZw99fqqD5pQqKi\njFd/PJLY6KovhQU47qAs2qUlkJdfyDmHdKhyvUtGdObFqav40zsLyE5PZETX4MM8LiaKMwZ92zl+\n3tCOPDtpBTcc04N3cvI4fWB7kuJi+NGR3eiakUy7tAS6ZCQz6A8fMmnZJoWCNGs1DYUEYB1wZOjx\nBiAROI0gJBQKUiOtkuP2uk5MdBQ/P7EPU5Zvplc1N9j1y05jcKd0Zq7cyjmHdCCqkjMKgCtHdWHM\nV8u55ulpFBSXcd7QjkBwn8WJFYYZ79uuBZOXbd63HRJpYvYaCmYWDcxx9/vroR4RAM4cnF3tpbC7\nXTO6G7e+PIvzqjmj6Nw6me8dlMWH89fRPTOZIZ0qn3r00K6teW7yCopKy4iPUb+CNE97vezC3cuA\ni+qhFpF9dnL/dsz+3fF0bFX1TW0AV4eujLpgWMcq7+Qe0a0VRaXlzF6159iPIs1HTZuPJpjZ/wEv\nATt3L3T3GXVSlcg+qMlf9cO7tuLVH49kQIe0atcxg8nLNjG8a6vaLFGk0ahpKAwKff1DhWUOHFO7\n5YjUnUM6t6z2+fSkOHpnpTL5m83cCExYspGHPl3MPy4aTJvUhPopUiTCahQK7n50XRci0hCM6Naa\nF6cGA/Bd99wM8neV8J8vvuGXJx8U6dJE6kWNbuU0sywze9zM3gs97mtmmqNZmpxDu7aisKScCx6d\nhLtzeI8Mnp20gq0FxZEuTaRe1PT+/qeAD4Ddw2UuQvMpSBO0uy9h084iHrxoML85tS8FxWXhO6Qr\ns2lHEd//zyS+XLyxnqoUqTs1DYUMd3+Z0BSc7l4KaDQxaXJap8Rz/tAO/OaUvhzduw2926byvb5Z\nPDlhOTuKSit9zd8/XMSEJZv4ycuz2LKz+jOKuavzWZuvqUik4appKOw0s9aE5lYwsxHAAV23Z2bR\nZjbTzN4OPe5qZpPNbImZvWRme7/LSaQO/PXcgfzg8K7hx9cd1Z38XSX85o25vDl7DTm5+eHZ4uat\nyefFqSs57qA2bNlZzO/enFfVZlmzdRfnPDyR8x/9iu2FJVWuB7B5ZzHLN+6sdh2RulDTULgVeBPo\nZmYTgKcJpug8EDcDCyo8vge43917EAzRrT4LaRAGd2rJWYOzeX3mam56YSan/d+XXPP0NNZvK+TO\nt+bTMimOe88fxI3H9OTN2Wt4bUYuG3cUkb/rux/893+0CHdYvXUXv35jbpXTkLo7Vz41lZP/8QWL\n1lU/xFhZubNkvYYhk9pjNZkf18wSgBuAEwgGwvsKeGh/p+Q0sw7AGODPBIFzGsHQGW3dvdTMDgN+\n7+4nVLedoUOH+rRp0/anBJF9trOolNVbd/HZwvXc++EioszYVVLGX87qz8WHdqKkrJyz/zWRnNXf\nnkSfPTibe84dwNINOzjpwS+4+vCupCbEct9Hi/jjGQdjZrwwZSW9slK57/yBmBkfz1/H1U9PIzba\n6NAyiXE3jKJFQuWTBt317gIeHb+MBy4YVO0d4GXlzofz1nJEr0yS42t6Jbo0VWY23d2HVvZcTX87\nnga2AX8JPb4YeIZgYLz98QBwO7B7YJvWwNZQXwVALlDpb7iZXQtcC9CpU6f9fHuRfZccH0OvrFR6\nZaVy7EFZ/HzsHCC4SxogNjqKp64cxofz11FaVs7SDcEQ3psLiikrd1LjY7j+6B6kJsQycelGfhOa\nJCg7PZHXZ65mWJdWXDisI/d9tIjOrZO46+z+XPb4FG59aRbnHtKRqcuDcZl+efJBREcZefm7eHLi\ncuJiorh97Bw6tExkaJfKb7p7aeoqfvl6Dkf0yuTxy4cSG115I4G788//LmFwp5bhYcqlealpKPRz\n974VHv/XzObvzxua2anAenefbmZH7evr3f0x4DEIzhT2pwaRA9U9M4WxPx6Ju39n2IzWKfFcNPzb\nP1Z6t03lV6/nUO7wi5P6kJ4UdJX946LBjJm4nOMOymJgh3Que2IKf3x7PlsKipmft437zh/IyO4Z\n/OqUg7jzrfl8vGB9eFrSuJhgwMAHP16Mu/P6daO48YWZXPvMdG45rifLNuxkV3EZPz2hF21SEygs\nKeOhTxeTmRrP+EUb+O24ufzlrP6YGfm7SmiREBPeh88XbeDvHy4iLiYIuJHdqw6Ge97/mnX5hfzl\n7P7VzkFRWlbO2m2F35meVRqumobCDDMb4e6TAMzsUGB/221GAaeb2ckEo6+2AB4E0s0sJnS20AFY\nvZ/bF6k3VY2jtNtFwzvRKjmO93LyuHxkl/DyNqkJ/OyEPuHH954/kBMeGM/fPlhIt8zk8NDfV4zs\nQru0RDJT4+iXncbv35zPw8i3NJwAABGzSURBVJ8tJTUhhlem53LpiM70y07jiSuGcda/JvDbcfNI\nioumtMxZtnEHz109gucmryQvv5Dnrz6UL5ds5F+fLSV3yy5Wbi5gxaYCbji6B7ed0JvycudvHyyk\nY6tEEmOjuWbMNB659BDWbyvio/nrGNmjNZcdFuxDTm4+D3+2FIDcLbv49+VDq5wX+7dvzuOlqau4\n/4JBnD6wfaXrSMNR0z6FBUBvYGVoUSdgIVAKuLsP2K83D84UbnP3U83sFeBVd3/RzB4hGJn1X9W9\nXn0K0pS8PzePG56fyUMXDeak/pXPTFdUWsb5j05i9qqtJMVFM/72o8MTFm0rLCG/oITs9ETezsnj\nphdmct4hHfjvwvX0ykrl+WtGUF7u3DZ2Np8t3MDQzi0pLivns4Ub+M9lQykqLef652dw/wXBWcp5\nj3zFys0FACTGRlNUWsYL14xgeNdWXPTvSSxat4PbT+jNb8bNpUvrZDq0TOTrtdvJTI3nxWtHkBQX\nw+J12znhgfEkxcVQUFzKvecPZEinljw1cXkQLJccQmZqUP/OolLemr2GMwZlkxhX/XhWGsn2wFTX\np1DTUOhc3fPuvmI/CzuKb0OhG/Ai0AqYCVzi7kXVvV6hIE3N9sISUqvoVN4tL38XFz42iUsO7cw1\nR1Q9L/Zd7y3g0c+XAfDadSMZ0ul/x34qLCnj3EcmsnJTAelJcSTERvHezUcQHWXkbingjZmrObxn\nJt0zkzntoS8pKi3n1u/14mdj5/DHMw7m0sO68PmiDfzi1Tm0SIyla0Yy789by7lDOvC38wZy9Zhp\nTF62ifduGc3tY+fw1bJNAESHzrBO6t+Ohy4aDMDPXpnNK9NzOXtINveeN7DKs7DVW3dxyj++4Jwh\nHfjNqX0rXWe3Jyd8Q3J8DOeH5tCoytr8QpZt2MHIGvSj7CwqbfSd9QccCg2VQkGaqz37MipTVu7c\n+vIskuKiuevsqk/mV20u4JR/fMG2wlIevfQQTji4baXr5eTmc/bDEygpc7plJvPBLUdU2mF974cL\neejTJVx+WGfGfLWCn53Qm+uP7kFhSRl3vjWPVslxXHZYF16csor7P17Ek1cMo6i0jB89O4PeWaks\nXLede87pzwXDKr+Q5PrnZ/DOnDwA7jq7/3f6cCqavWorZ/xzAgCPXHLIdyZUqqi83DnzXxOYk5vP\ngxcO+s6sfXt6fvJKfvfmXB67bChH925T5Xrrtxdyw3MzueaIbnyvb1aV65WXO7e9MpuD2rWoNuAB\nXpuRy+L1wdnZ3o793igURKRaU77ZzJdLNvKT43pW+4Hz+Jff8Me35/Ofy4ZyXBUfdqVl5Vz878lM\nWb6ZrBbxfHbb0ZU2BxWXlnPKP75gZ1Epu0rKyG6ZyNgfjeTqMdOYunwzj18+jHbpCcRFR9GhZSJm\nxldLN3HRvydx0zE9mJ2bz8SlG/nnxUPYXljKlG82c3SfTE7s1w5355yHJ7JycwHZ6YksXr+DsT8a\nSVm58/DnS0iIieav5w4gJjqKsdNzue2V2bRPS2DjjmKeuWo4h1YyJev6bYUce+/nbC8qJT0plndu\nGk12emKlP4NbXpzJG7PWkBQXzWvXjaRP2xaVrvfytFXcHrqK7eHvD6my2XDV5gKOu+9zikrL+fUp\nB4XnB9lfCgURqTUbtheF+wGqsja/kKvGTOX6o3twchUfdADTV2zm3Ee+Ii46induOpwebVLZuKOI\nU/7xBeu2fdt6PLxrK35+Yh9+9XoO2wtL+eSnR1JUWs5Z/5zAstCd37uvzvrjmf1okRDDzS/O4q/n\nDOCo3pmc/n8T2FZYQkFxGSnxMewoKuXCYR359al9Oebvn9E+PZEnrxjGOY9MZNOOYkb3zGDxuh2U\nu/OnM/txaLfW3PD8DD6cv45HLz2EG5+fSY82Kbz8w8OIi/nu2dLEpRu5+N+TufjQTnw8fx0JsdG8\necMo0pPivnOGl19QwjH3fkbn1kk4sHDtdt64flSlU9BePWYqE5du4pDOLZm4dBMvXjuCYVVcflwT\nCgURabBenraKjJQ4junz7ZlHXv4upnwT3Jexblshj41fxsYdwbhS//r+kHDQrNpcwIfz13Fo11b0\naJPCDc/P5OMF60iOi6ZbZgrjrh9FVJSRk5vPr97I4YSD23LZYZ15bPwyHvp0Sbi5anefy6rNBfzg\nqakUlpbRq00qSzfsYOXmAs4a3IFXZ+Tyk+N6cfNxPXkvJ48fPzeDti0SKC0vDwJqcDZXH96NK5+a\nQnFZOR/95Ejm523jwkcn0ToluBR5w/YiRvUILjV+btIKnpm0grduPJyMlHhOfehLogzapyeyflsR\nXTOS+dkJvdmwvYirn57GL07qw0WHduL0h75kV0kZ79w0OnyRwb5SKIhIo7ajqJR/j1/GjqJSfn3K\nQVU2cZWUlXPbK7N5a/YaXvrhYVX+Ne3u/PSV2bw2YzVnDmrPAxcOrnS97YUl/OK1HN6ek0e3jGTe\nu2V0+KqnZyatYNLSTbRIjKWguJR35uRRWh58nj55xTCO7hP0Obw/dy3PT1lJZko8qQkxvDYjNzy4\n4iUjOvOHM/oBMGPlFv78zgISY6PJSInji8Ub2bSzmOS4aNqnJ/LuzaOJjY5i/pptnPWvCdxxUh+u\nHNW1kqr3TqEgIs2Gu7NxR/Fem7iKS8sZOz2Xk/u3Dd9UWNX2Ppy/jp5tUuiWmVLleqs2F/Do+KUk\nx8Xwi2omZdqys5gHP1nM7NytPHXFcNKSKr/abHthCf8ev4xXZ6zmgQsHfSfgVmzaSefWydXuX3UU\nCiIiElZdKNR0lFQREWkGFAoiIhKmUBARkTCFgoiIhCkUREQkTKEgIiJhCgUREQlTKIiISJhCQURE\nwhQKIiISplAQEZEwhYKIiIQpFEREJEyhICIiYQoFEREJUyiIiEiYQkFERMIUCiIiEqZQEBGRMIWC\niIiEKRRERCRMoSAiImEKBRERCVMoiIhImEJBRETCFAoiIhKmUBARkTCFgoiIhNV7KJhZRzP7r5nN\nN7N5ZnZzaHkrM/vIzBaHvras79pERJq7SJwplAI/dfe+wAjgejPrC9wBfOLuPYFPQo9FRKQe1Xso\nuHueu88Ifb8dWABkA2cAY0KrjQHOrO/aRESau4j2KZhZF2AwMBnIcve80FNrgawqXnOtmU0zs2kb\nNmyolzpFRJqLiIWCmaUArwK3uPu2is+5uwNe2evc/TF3H+ruQzMzM+uhUhGR5iMioWBmsQSB8Jy7\nvxZavM7M2oWebwesj0RtIiLNWSSuPjLgcWCBu99X4ak3gctD318OjKvv2kREmruYCLznKOBSIMfM\nZoWW/RK4G3jZzK4CVgDnR6A2EZFmrd5Dwd2/BKyKp4+tz1pEROS7dEeziIiEKRRERCRMoSAiImEK\nBRERCVMoiIhImEJBRETCFAoiIhKmUBARkTCFgoiIhCkUREQkTKEgIiJhCgUREQlTKIiISJhCQURE\nwhQKIiISplAQEZEwhYKIiIQpFEREJEyhICIiYQoFEREJUyiIiEiYQkFERMIUCiIiEqZQEBGRMIWC\niIiEKRRERCRMoSAiImEKBRERCVMoiIhImEJBRETCFAoiIhKmUBARkTCFgoiIhCkUREQkTKEgIiJh\nDSoUzOxEM1toZkvM7I5I1yMi0tw0mFAws2jgn8BJQF/gIjPrG9mqRESalwYTCsBwYIm7L3P3YuBF\n4IwI1yQi0qzERLqACrKBVRUe5wKH7rmSmV0LXBt6uMPMFu7n+2UAG/fztQ1NU9oXaFr7o31pmJr7\nvnSu6omGFAo14u6PAY8d6HbMbJq7D62FkiKuKe0LNK390b40TNqXqjWk5qPVQMcKjzuElomISD1p\nSKEwFehpZl3NLA64EHgzwjWJiDQrDab5yN1LzewG4AMgGnjC3efV4VsecBNUA9KU9gWa1v5oXxom\n7UsVzN1rc3siItKINaTmIxERiTCFgoiIhDXLUGjMw2mYWUcz+6+ZzTezeWZ2c2h5KzP7yMwWh762\njHStNWVm0WY208zeDj3uamaTQ8fnpdCFBw2emaWb2Vgz+9rMFpjZYY31uJjZT0K/X3PN7AUzS2hM\nx8XMnjCz9WY2t8KySo+FBf4R2q85ZjYkcpX/ryr25W+h37M5Zva6maVXeO4XoX1ZaGYn7Ov7NbtQ\naALDaZQCP3X3vsAI4PpQ/XcAn7h7T+CT0OPG4mZgQYXH9wD3u3sPYAtwVUSq2ncPAu+7ex9gIME+\nNbrjYmbZwE3AUHfvR3Dhx4U0ruPyFHDiHsuqOhYnAT1D/64FHq6nGmvqKf53Xz4C+rn7AGAR8AuA\n0GfBhcDBodf8K/SZV2PNLhRo5MNpuHueu88Ifb+d4IMnm2AfxoRWGwOcGZkK942ZdQBOAf4TemzA\nMcDY0CqNYl/MLA04AngcwN2L3X0rjfS4EFyZmGhmMUASkEcjOi7uPh7YvMfiqo7FGcDTHpgEpJtZ\nu/qpdO8q2xd3/9DdS0MPJxHc1wXBvrzo7kXu/g2whOAzr8aaYyhUNpxGdoRqOSBm1gUYDEwGstw9\nL/TUWiArQmXtqweA24Hy0OPWwNYKv/CN5fh0BTYAT4aawv5jZsk0wuPi7quBvwMrCcIgH5hO4zwu\nFVV1LBr7Z8IPgPdC3x/wvjTHUGgSzCwFeBW4xd23VXzOg+uMG/y1xmZ2KrDe3adHupZaEAMMAR52\n98HATvZoKmpEx6UlwV+cXYH2QDL/23zRqDWWY7E3ZvYrgibl52prm80xFBr9cBpmFksQCM+5+2uh\nxet2n/KGvq6PVH37YBRwupktJ2jGO4agXT491GwBjef45AK57j459HgsQUg0xuNyHPCNu29w9xLg\nNYJj1RiPS0VVHYtG+ZlgZlcApwLf929vODvgfWmOodCoh9MItbk/Dixw9/sqPPUmcHno+8uBcfVd\n275y91+4ewd370JwHD519+8D/wXODa3WWPZlLbDKzHqHFh0LzKcRHheCZqMRZpYU+n3bvS+N7rjs\noapj8SZwWegqpBFAfoVmpgbJzE4kaHY93d0LKjz1JnChmcWbWVeCzvMp+7Rxd292/4CTCXrslwK/\ninQ9+1j74QSnvXOAWaF/JxO0xX8CLAY+BlpFutZ93K+jgLdD33cL/SIvAV4B4iNdXw33YRAwLXRs\n3gBaNtbjAtwJfA3MBZ4B4hvTcQFeIOgPKSE4i7uqqmMBGMEViUuBHIKrriK+D3vZlyUEfQe7PwMe\nqbD+r0L7shA4aV/fT8NciIhIWHNsPhIRkSooFEREJEyhICIiYQoFEREJUyiIiEiYQkGaNTObGPra\nxcwuruVt/7Ky9xJpyHRJqghgZkcBt7n7qfvwmhj/diygyp7f4e4ptVGfSH3RmYI0a2a2I/Tt3cBo\nM5sVmksgOjRm/dTQmPU/DK1/lJl9YWZvEtzli5m9YWbTQ/MPXBtadjfBKKOzzOy5iu8VunP2b6G5\nCnLM7IIK2/7Mvp2T4bnQHcWY2d0WzKExx8z+Xp8/I2leYva+ikizcAcVzhRCH+757j7MzOKBCWb2\nYWjdIQRj2X8TevwDd99sZonAVDN71d3vMLMb3H1QJe91NsHdzwOBjNBrxoeeG0wwFv4aYAIwyswW\nAGcBfdzdK06oIlLbdKYgUrnjCcbDmUUwNHlrgnFkAKZUCASAm8xsNsG49h0rrFeVw4EX3L3M3dcB\nnwPDKmw7193LCYYv6EIwdHUh8LiZnQ0UVLJNkVqhUBCpnAE3uvug0L+u7r77TGFneKWgL+I44DB3\nHwjMBBIO4H2LKnxfBuzutxhOMPLqqcD7B7B9kWopFEQC24HUCo8/AH4cGqYcM+sVmjRnT2nAFncv\nMLM+BFOk7lay+/V7+AK4INRvkUkwY1uVI1mG5s5Ic/d3gZ8QNDuJ1An1KYgE5gBloWagpwjmdegC\nzAh19m6g8ukn3wd+FGr3X0jQhLTbY8AcM5vhwZDgu70OHAbMJhjx9nZ3XxsKlcqkAuPMLIHgDObW\n/dtFkb3TJakiIhKm5iMREQlTKIiISJhCQUREwhQKIiISplAQEZEwhYKIiIQpFEREJOz/AcP9/3/0\nfPC8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(ppl_list)\n",
        "plt.ylim((0, 100))\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('perplexity')\n",
        "plt.title('train perplexity')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wYFbHp-ltIbE"
      },
      "source": [
        "### テストデータで評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "iNA2ySg2Qi9p",
        "outputId": "cb847caf-c1b1-4e9f-c064-c1fe7e2bf3ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| test perplexity 45.45 |\n"
          ]
        }
      ],
      "source": [
        "ppl = eval_perplexity(model, test_iter)\n",
        "print(f'| test perplexity {ppl:.2f} |')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bQr-lxn534_n"
      },
      "source": [
        "## 文章生成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "colab_type": "code",
        "id": "LtHts3eS3_X9",
        "outputId": "38f9285a-7ee4-4cea-8b52-b6c32aedebb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "私は、大みそかもお手伝いしたばかりの、いくらだのと信じて離れたいのに、やっぱり、――」「小んです」「え、こんどはそうです。」\n",
            "「そんなら。」\n",
            "こんどは、黙ってつとめているのである。\n",
            "「小説を知ることはあるまい。」\n",
            "「だと思ってるよ。」\n",
            "思いめくって、そうして私には、「世相かインバータ」という形が、唯一の返事をしているつもりであるが、私はこのごろその後も疑ってしまったのに、説教をしたように、黙っていた。\n",
            "私は、頭が親のみちるを感じた。\n",
            "「だから、それでも、もう五時、きょうは買いましたが、僕たちが下宿にハイリスクですから、\n"
          ]
        }
      ],
      "source": [
        "def text_generate(model, start_ids, length=100, skip_ids=None,\n",
        "                  prob=True, top=None, seed=2020):\n",
        "  word_ids = []\n",
        "  word_ids += start_ids\n",
        "\n",
        "  random.seed(seed)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    hidden = None\n",
        "    input_id = start_ids\n",
        "    while len(word_ids) < length:\n",
        "      input = torch.tensor(input_id, dtype=torch.long,\n",
        "                           device=device).view(1, -1).t().contiguous()\n",
        "      output, hidden = model(input, hidden)\n",
        "      \n",
        "      p_list = F.softmax(output[-1].flatten(), dim=0)\n",
        "\n",
        "      if top is not None:\n",
        "        sorted_p_list = p_list.sort(descending=True).values[:top]\n",
        "        sorted_idx = p_list.sort(descending=True).indices[:top]\n",
        "        p_list = sorted_p_list / sorted_p_list.sum()\n",
        "\n",
        "      if prob:\n",
        "        while True:\n",
        "          rnd = random.random()\n",
        "          p_sum = 0\n",
        "          for idx, p in enumerate(p_list):\n",
        "            p_sum += p.item()\n",
        "            if rnd < p_sum:\n",
        "              sampled = idx if top is None else sorted_idx[idx].item()\n",
        "              break\n",
        "          if (skip_ids is None) or (sampled not in skip_ids):\n",
        "            break\n",
        "      else:\n",
        "        if skip_ids is not None:\n",
        "          p_list[skip_ids] = 0\n",
        "          sampled = p_list.argmax().item()\n",
        "\n",
        "      word_ids.append(sampled)\n",
        "      input_id = sampled\n",
        "    \n",
        "  return word_ids\n",
        "\n",
        "\n",
        "save_path = './data/model/weights.pth'\n",
        "model = MyLSTM(vocab_size, emb_dim, hidden_size, dropout, weight_tied=True)\n",
        "model.load_state_dict(torch.load(save_path))\n",
        "model.to(device)\n",
        "\n",
        "start_words = ['私', 'は']\n",
        "\n",
        "start_ids = []\n",
        "for start_word in start_words:\n",
        "  if start_word not in word_to_id:\n",
        "    raise KeyError(start_word + ' is not in the dictionary!')\n",
        "  start_ids.append(word_to_id[start_word])\n",
        "skip_ids = [word_to_id['<unk>']]\n",
        "\n",
        "word_ids = text_generate(model, start_ids, length=173,\n",
        "                         skip_ids=skip_ids, top=None, seed=1)\n",
        "text = ''.join([id_to_word[w_id] for w_id in word_ids])\n",
        "text = text.replace('。', '。\\n').replace('。\\n」', '。」\\n')\n",
        "print(text)"
      ]
    }
  ]
}